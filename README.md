# Practicas-Empresa-2024

<u>Semana 1 (21/04 - 25/04)</u>
El lunes a las 10:00 he quedado con Consolación Guil, nuestra tutora de la empresa, la cual nos ayuda a encaminarnos en este proyecto de investigación. El proyecto se basa en la implementación de XAI (Inteligencia Artificial Explicable) para realizar razonamientos contrafactuales en base a una encuesta que se hizo anteriormente a un grupo de alumnos de la universidad. Para ello se hara un procesamiento de datos previo para hacer un programa de Machine Learning donde se tendrá que probar distintos modelos de clasificación y de razonamiento.

Se ha empezado leyendo lo que dejo explicado la anterior alumna en prácticas. En su carpeta de Google Drive, a la cual tengo acceso, ya tenía empezado este proyecto. Ella dejó hecho hasta la parte de codificación de datos para que el algoritmo de ML pudiera leerlos.

En los siguientes días hasta hoy, viernes, se ha implementado la parte de preprocesamiento de datos orientada a objetos, ya que todo el codigo está en Google Colab y está desparramado en distintos archivos de esta plataforma. Más tarde se empezará a hacer el modelado con los distintos algoritmos existentes (bosques aleatoria, regresion lineal, etc.).

<u>Semana 2-3 (28/04 - 02/05 | 05/05 - 09/05)</u>
Este reporte es de dos semanas debido al apagón de la semana 2 el lunes 28 de abril a las 12:30 y al puente del dia del trabajador. Durante la semana dos, se empezó a plantear el código de manera más genérica para futuros estudios de datos haciendo distintas clases que contienen los distintos métodos para las fases de análisis de datos (Preprocesamiento, Clasificación y, aparte, el razonamiento Contrafactual). Debido a los sucesos previamente dichos, solo se trabajó 1 día y medio por lo que lo único que se hizo fue terminar de implementar este código para poder procesar correctamente los datos. Como punto aparte, el miércoles vino la anterior alumna en prácticas para explicar el código que había hecho ella hasta el momento. Por desgracia, yo no podía estar presente debido a que tenía una tutoría ese día. Al volver, mi compañero me dijo que si voy avanzado, podía empezar el siguiente estudio sobre la igualdad de género. Este proyecto se nos planteó la semana 1 por encima como una de las dos opciones para estudiar durante nuestras prácticas. El proyecto consiste en con NLP (Procesamiento de Lenguaje Natural) interpretar si anuncios (empezando por textos/slogans) tienen sesgo de género. Conforme se desarrolle el proyecto, se ampliará a imágenes y después a videos.

En la semana 3 se siguió implementando el código y corrigiendo las partes que pudisen ser innecesarias. Cuando se terminó de hacer el código del primer proyecto (Estudio de conciencia ambiental en los alumnos de la universidad) se procedió a ampliar el código para el segundo proyecto. Para ello, por consejo de la tutora, Se inició investigando el funcionamiento de CountVectorizer y de TF-IDF, paquetes de vectorización de textos en Python. También fue necesario crear la base de datos, ya que después de buscar bases de datos similares, ninguna servía para ello. Al terminar de implementar, el viernes vino la tutora a hacer la revisión del progreso semanal y vimos que se planteaban problemas con ciertos paquetes que habria que solucionar. Por ejemplo que el paquete LIME, encargado de explicar la importancia de cada atributo a la hora de predecir/clasificar datos, no procesa variables categoricas. Pero si están codificadas al momento de declarar el explicador, los resultados del explicador se muestran codificados.

Durante la siguiente semana, se seguirán solucionando problemas volviendo a la base de datos del primer proyecto, ya que está compuesta casi en su totalidad de variables categoricas.

<u>Semana 4 (12/05 - 16/05)</u>
Esta semana se resolvió los problemas propuestos la semana pasada. Se cambiaron pequeños detalles que se recomendó por parte de la tutora de prácticas, Consolación Gil. Además de esto, se hizo un estudio de LIME con mayor atención debido a que en la implementación del código hubo que revisar y cambiar lo anteriormente programado. Al terminar, empecé a documentar todo lo hecho hasta ahora para no tener que hacer todo esto después, ya que es bastante hasta ahora. Lo que se documentó hasta ahora fue un tercio de lo que se ha hecho hasta ahora.

<u>Semana 5 (19/05 - 23/05)</u>
Durante esta semana solo se ha completado la documentación y se empezó la investigación de SHAP. No se ha hecho mucha más que eso debio a no invertir la misma cantidad de horas (+5 horas diarias por voluntad propia).

<u>Semana 6 (26/05 - 30/05)</u>
Se terminó la investigación de SHAP, concluyendo que en ciertos casos puede ser más útil que LIME. LIME ofrece un análisis de importancia de cada atributo de un marco de datos de manera local, es decir, por cada instancia, sin embargo, SHAP puede hacer ese análisis tanto local como. Además, el proceso de análisis de LIME es por regresión lineal a diferencia de SHAP, que es por una fórmula matemática a través de los valores Shaply. Se implementó dos metodos más en el código para poder hacer los análisis necesarios posteriormente. La siguiente tarea fue empezar una aplicación para hacer el proceso de preprocesamiento, explicación y razonamiento contrafactual. La cual se hará con Python y las librerias tkinter o ttbootstrap.

<u>Semana 7 (02/06 - 06/06)</u>
Debido a las complicaciones que se plantearon en la app y la larga duración del desarrollo de esta hasta su finalización, se pospondrá a la última semana de las prácticas si hay tiempo y si se da la ocasión. Aún así se ha llegado a hacer la parte de preprocesamiento y muestreo de datos. Se siguió entonces con el desarrollo e investigación de los tipos de modelos y los mejores modelos para, en este caso, la base de datos del proyecto de sostenibilidad. Para ello se cambió uno de los archivos para poder ver las métricas de los modelos dependiendo de que tipo sea (Arboles de decisión, Naive Bayes o Redes Neuronales)

<u>Semana 8 (09/06 - 13/06)</u>
Se terminó de cambiar el archivo que se mencionó la semana pasada (Modeling.py) para que se pudiese seleccionar un tipo de modelo de datos (Lineal, árboles de decisión, Naive Bayes, SVC o Redes Neuronales) y después seleccionar entre todos los posibles modelos que hay en Python del tipo seleccionado anteriormente. Las métricas del modelo se calcula con valores cruzados separando el marco de datos en fragmentos y utilizando una distinta combinación de estos como entrenamiento y prueba para una mayor precisión de las métricas. También se hizo el estudio de un cambio en el umbral de criterios mínimos para verificar que el umbral puesto por la anterior alumna en prácticas, Ainhoa, ya que este crea muy pocas muestras de clase positiva del atributo a estudiar. Por último, se hizo un estudio del mejor modelo de datos para 6 casos de marco de datos, siendo estos:
- Umbral mínimo 6 con y sin sobremuestreo
- Umbral mínimo 7 con y sin sobremuestreo
- Umbral mínimo 8 con y sin sobremuestreo
Y se estudió la influencia del modelo en las librerias SHAP y DiCE.